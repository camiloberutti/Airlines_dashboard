{"cells":[{"cell_type":"markdown","metadata":{"id":"aqxaxG-iNIeG"},"source":["# US Airline Dataset\n","\n","https://www.kaggle.com/datasets/shaivyac/us-airline-dataset"]},{"cell_type":"code","execution_count":91,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14586,"status":"ok","timestamp":1763822552040,"user":{"displayName":"Orz “Aden” Nichita","userId":"12778509813246526185"},"user_tz":-60},"id":"iw4xgKDOVOzR","outputId":"09338668-a444-4b2c-9b23-15ee82f9d09d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files downloaded:\n","['Airline_dataset.csv']\n"]}],"source":["# Install dependencies\n","!pip install -q kagglehub[pandas-datasets]\n","\n","import kagglehub\n","from kagglehub import KaggleDatasetAdapter\n","import os\n","import pandas as pd\n","\n","# Download dataset (returns local directory path)\n","path = kagglehub.dataset_download(\"shaivyac/us-airline-dataset\")\n","\n","# List files in the dataset to see what’s available\n","print(\"Files downloaded:\")\n","print(os.listdir(path))\n","\n","# Now, load a specific file (replace with actual filename you see printed)\n","file_to_load = os.path.join(path, \"Airline_dataset.csv\")  # Corrected filename\n","\n","# Load the dataset using pandas directly from the local path\n","\n","df = pd.read_csv(file_to_load)\n","\n","\n","####\n","df['FL_DATE'] = pd.to_datetime(df['FL_DATE'], format='%m/%d/%y')\n","cols = [\"AIRLINE_ID\", \"FLIGHT_NUM\", \"ORIGIN_SEQ_ID\",\"DEST_SEQ_ID\"]\n","df[cols] = df[cols].astype(int)\n","df['DEP_DELAY'] = df['DEP_DELAY'].fillna(0)\n","df['ARR_DELAY'] = df['ARR_DELAY'].fillna(0)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"nowjiF63ZWA1","executionInfo":{"status":"ok","timestamp":1763822552059,"user_tz":-60,"elapsed":9,"user":{"displayName":"Orz “Aden” Nichita","userId":"12778509813246526185"}}},"execution_count":91,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s9loTRlGJkqc"},"source":["## Dataset content:\n","\n","- FL_DATE:\n","The date of the flight.Instead of storing all attributes to store date we use a single attribute.Date of the Flight in yyyymmdd Airline Reporting Unique.\n","- AIRLINE_ID:\n","An identification number assigned by US DOT to identify a unique airline (carrier). It has a single value for each individual carrier.\n","- TAIL_NUM:\n","An identification number to store the tail number of the airlines.\n","- FLIGHT_NUM:\n","The flight number is stored in form of unique value for each flight.\n","- ORIGIN_SEQ_ID:\n","Unique id for storing each origin airport of the flight.\n","- ORIGIN_AIRPORT:\n","Stores the origin airport.It can be used for displaying the airport which are easier to understand. For example, JFK.\n","- DEST_SEQ_ID:\n","Unique id for storing each destination airport of the flight.\n","- DEST_AIRPORT:\n","Stores the destination airport.It can be used for displaying the airport which are easier to understand.For example, JFK.\n","- DEP_TIME:\n","Actual Departure Time in local time: hhmm"]},{"cell_type":"markdown","metadata":{"id":"NtZXf2UFIBn9"},"source":["Preprocessing:"]},{"cell_type":"code","execution_count":92,"metadata":{"id":"knnojWBvIBCN","executionInfo":{"status":"ok","timestamp":1763822552092,"user_tz":-60,"elapsed":29,"user":{"displayName":"Orz “Aden” Nichita","userId":"12778509813246526185"}}},"outputs":[],"source":["cols = [\"AIRLINE_ID\", \"FLIGHT_NUM\", \"ORIGIN_SEQ_ID\",\"DEST_SEQ_ID\"]\n","df[cols] = df[cols].astype(int)"]},{"cell_type":"code","execution_count":93,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1763822552125,"user":{"displayName":"Orz “Aden” Nichita","userId":"12778509813246526185"},"user_tz":-60},"id":"pFqcHbTVVPXa","outputId":"2a4c9de4-8ba3-48f8-c02f-e4109fd25e57"},"outputs":[{"output_type":"display_data","data":{"text/plain":["         Unnamed: 0    FL_DATE  AIRLINE_ID TAIL_NUM  FLIGHT_NUM  \\\n","0                 0 2018-08-01       19805   N956AN        1587   \n","1                 1 2018-08-01       19805   N973AN        1588   \n","2                 2 2018-08-01       19805    N9006        1590   \n","3                 3 2018-08-01       19805   N870NN        1591   \n","4                 4 2018-08-01       19805   N9023N        1593   \n","...             ...        ...         ...      ...         ...   \n","1204820     1226363 2020-01-05       19977   N66831        1598   \n","1204821     1226364 2020-01-05       19977   N57111        1597   \n","1204822     1226365 2020-01-05       19977   N34455        1592   \n","1204823     1226366 2020-01-05       19977   N16234        1591   \n","1204824     1226367 2020-01-05       19977   N36444        1588   \n","\n","         ORIGIN_SEQ_ID ORIGIN_AIRPORT  DEST_SEQ_ID DEST_AIRPORT  DEP_TIME  \\\n","0              1247805            JFK      1410702          PHX    1649.0   \n","1              1410702            PHX      1161802          EWR    1541.0   \n","2              1104205            CLE      1129806          DFW     741.0   \n","3              1484306            SJU      1129806          DFW     944.0   \n","4              1042302            AUS      1330303          MIA     556.0   \n","...                ...            ...          ...          ...       ...   \n","1204820        1477104            SFO      1449202          RDU    2257.0   \n","1204821        1161802            EWR      1393007          ORD     628.0   \n","1204822        1226603            IAH      1226402          IAD     729.0   \n","1204823        1129202            DEN      1530402          TPA     756.0   \n","1204824        1393007            ORD      1142307          DSM    2125.0   \n","\n","         DEP_DELAY  ARR_TIME  ARR_DELAY  WEATHER_DELAY  \n","0              9.0    2006.0       44.0       0.000000  \n","1             29.0    2350.0       53.0       0.000000  \n","2             -3.0     938.0       -2.0       4.030195  \n","3             44.0    1347.0       43.0       0.000000  \n","4             -4.0     951.0       -2.0       4.030195  \n","...            ...       ...        ...            ...  \n","1204820       -3.0     642.0      -18.0       4.030195  \n","1204821       13.0     751.0        0.0       4.030195  \n","1204822       -1.0    1124.0       -1.0       4.030195  \n","1204823       -1.0    1302.0      -18.0       4.030195  \n","1204824       -5.0    2242.0      -14.0       4.030195  \n","\n","[1204825 rows x 14 columns]"],"text/html":["\n","  <div id=\"df-7f3c771a-3314-4bea-bf56-66d838d575a9\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>FL_DATE</th>\n","      <th>AIRLINE_ID</th>\n","      <th>TAIL_NUM</th>\n","      <th>FLIGHT_NUM</th>\n","      <th>ORIGIN_SEQ_ID</th>\n","      <th>ORIGIN_AIRPORT</th>\n","      <th>DEST_SEQ_ID</th>\n","      <th>DEST_AIRPORT</th>\n","      <th>DEP_TIME</th>\n","      <th>DEP_DELAY</th>\n","      <th>ARR_TIME</th>\n","      <th>ARR_DELAY</th>\n","      <th>WEATHER_DELAY</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2018-08-01</td>\n","      <td>19805</td>\n","      <td>N956AN</td>\n","      <td>1587</td>\n","      <td>1247805</td>\n","      <td>JFK</td>\n","      <td>1410702</td>\n","      <td>PHX</td>\n","      <td>1649.0</td>\n","      <td>9.0</td>\n","      <td>2006.0</td>\n","      <td>44.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2018-08-01</td>\n","      <td>19805</td>\n","      <td>N973AN</td>\n","      <td>1588</td>\n","      <td>1410702</td>\n","      <td>PHX</td>\n","      <td>1161802</td>\n","      <td>EWR</td>\n","      <td>1541.0</td>\n","      <td>29.0</td>\n","      <td>2350.0</td>\n","      <td>53.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2018-08-01</td>\n","      <td>19805</td>\n","      <td>N9006</td>\n","      <td>1590</td>\n","      <td>1104205</td>\n","      <td>CLE</td>\n","      <td>1129806</td>\n","      <td>DFW</td>\n","      <td>741.0</td>\n","      <td>-3.0</td>\n","      <td>938.0</td>\n","      <td>-2.0</td>\n","      <td>4.030195</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2018-08-01</td>\n","      <td>19805</td>\n","      <td>N870NN</td>\n","      <td>1591</td>\n","      <td>1484306</td>\n","      <td>SJU</td>\n","      <td>1129806</td>\n","      <td>DFW</td>\n","      <td>944.0</td>\n","      <td>44.0</td>\n","      <td>1347.0</td>\n","      <td>43.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2018-08-01</td>\n","      <td>19805</td>\n","      <td>N9023N</td>\n","      <td>1593</td>\n","      <td>1042302</td>\n","      <td>AUS</td>\n","      <td>1330303</td>\n","      <td>MIA</td>\n","      <td>556.0</td>\n","      <td>-4.0</td>\n","      <td>951.0</td>\n","      <td>-2.0</td>\n","      <td>4.030195</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1204820</th>\n","      <td>1226363</td>\n","      <td>2020-01-05</td>\n","      <td>19977</td>\n","      <td>N66831</td>\n","      <td>1598</td>\n","      <td>1477104</td>\n","      <td>SFO</td>\n","      <td>1449202</td>\n","      <td>RDU</td>\n","      <td>2257.0</td>\n","      <td>-3.0</td>\n","      <td>642.0</td>\n","      <td>-18.0</td>\n","      <td>4.030195</td>\n","    </tr>\n","    <tr>\n","      <th>1204821</th>\n","      <td>1226364</td>\n","      <td>2020-01-05</td>\n","      <td>19977</td>\n","      <td>N57111</td>\n","      <td>1597</td>\n","      <td>1161802</td>\n","      <td>EWR</td>\n","      <td>1393007</td>\n","      <td>ORD</td>\n","      <td>628.0</td>\n","      <td>13.0</td>\n","      <td>751.0</td>\n","      <td>0.0</td>\n","      <td>4.030195</td>\n","    </tr>\n","    <tr>\n","      <th>1204822</th>\n","      <td>1226365</td>\n","      <td>2020-01-05</td>\n","      <td>19977</td>\n","      <td>N34455</td>\n","      <td>1592</td>\n","      <td>1226603</td>\n","      <td>IAH</td>\n","      <td>1226402</td>\n","      <td>IAD</td>\n","      <td>729.0</td>\n","      <td>-1.0</td>\n","      <td>1124.0</td>\n","      <td>-1.0</td>\n","      <td>4.030195</td>\n","    </tr>\n","    <tr>\n","      <th>1204823</th>\n","      <td>1226366</td>\n","      <td>2020-01-05</td>\n","      <td>19977</td>\n","      <td>N16234</td>\n","      <td>1591</td>\n","      <td>1129202</td>\n","      <td>DEN</td>\n","      <td>1530402</td>\n","      <td>TPA</td>\n","      <td>756.0</td>\n","      <td>-1.0</td>\n","      <td>1302.0</td>\n","      <td>-18.0</td>\n","      <td>4.030195</td>\n","    </tr>\n","    <tr>\n","      <th>1204824</th>\n","      <td>1226367</td>\n","      <td>2020-01-05</td>\n","      <td>19977</td>\n","      <td>N36444</td>\n","      <td>1588</td>\n","      <td>1393007</td>\n","      <td>ORD</td>\n","      <td>1142307</td>\n","      <td>DSM</td>\n","      <td>2125.0</td>\n","      <td>-5.0</td>\n","      <td>2242.0</td>\n","      <td>-14.0</td>\n","      <td>4.030195</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1204825 rows × 14 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f3c771a-3314-4bea-bf56-66d838d575a9')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7f3c771a-3314-4bea-bf56-66d838d575a9 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7f3c771a-3314-4bea-bf56-66d838d575a9');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-2d5a8a2c-5d58-4209-a3f8-3b1010c459c0\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d5a8a2c-5d58-4209-a3f8-3b1010c459c0')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-2d5a8a2c-5d58-4209-a3f8-3b1010c459c0 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_ca5ba8b2-ff5e-4ead-bbcd-640df3ee3bf4\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_ca5ba8b2-ff5e-4ead-bbcd-640df3ee3bf4 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{}}],"source":["display(df)"]},{"cell_type":"markdown","source":["we noticed a weird number and we kill it"],"metadata":{"id":"K_uvOsEajinQ"}},{"cell_type":"code","source":["df.loc[(df['WEATHER_DELAY'] >= 4.03) & (df['WEATHER_DELAY'] <= 4.04), 'WEATHER_DELAY'] = 0\n"],"metadata":{"id":"FldHzZ0FhGbw","executionInfo":{"status":"ok","timestamp":1763822552134,"user_tz":-60,"elapsed":6,"user":{"displayName":"Orz “Aden” Nichita","userId":"12778509813246526185"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dSu4gdK_h1ub","executionInfo":{"status":"ok","timestamp":1763822552142,"user_tz":-60,"elapsed":3,"user":{"displayName":"Orz “Aden” Nichita","userId":"12778509813246526185"}}},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":["Airport data:"],"metadata":{"id":"O7UXILue420J"}},{"cell_type":"code","source":["import pandas as pd\n","import requests\n","from io import StringIO\n","\n","# -----------------------------\n","# 1. Download the airports data\n","# -----------------------------\n","url = \"https://ourairports.com/data/airports.csv\"\n","csv_data = requests.get(url).text\n","airports = pd.read_csv(StringIO(csv_data))\n","\n","# -----------------------------\n","# 2. Your list of IATA codes\n","# -----------------------------\n","iata_codes = {\n"," 'ABE','ABI','ABQ','ABR','ABY','ACK','ACT','ACV','ACY','ADK','ADQ','AEX','AGS','AKN','ALB','ALO',\n"," 'ALW','AMA','ANC','APN','ART','ASE','ATL','ATW','ATY','AUS','AVL','AVP','AZA','AZO','BDL','BET',\n"," 'BFF','BFL','BFM','BGM','BGR','BHM','BIL','BIS','BJI','BKG','BLI','BLV','BMI','BNA','BOI','BOS',\n"," 'BPT','BQK','BQN','BRD','BRO','BRW','BTM','BTR','BTV','BUF','BUR','BWI','BZN','CAE','CAK','CDC',\n"," 'CDV','CGI','CHA','CHO','CHS','CID','CIU','CKB','CLE','CLL','CLT','CMH','CMI','CMX','CNY','COD',\n"," 'COS','COU','CPR','CRP','CRW','CSG','CVG','CWA','CYS','DAB','DAL','DAY','DBQ','DCA','DEN','DFW',\n"," 'DHN','DIK','DLG','DLH','DRO','DRT','DSM','DTW','DUT','DVL','EAR','EAT','EAU','ECP','EGE','EKO',\n"," 'ELM','ELP','ERI','ESC','EUG','EVV','EWN','EWR','EYW','FAI','FAR','FAT','FAY','FCA','FLG','FLL',\n"," 'FLO','FNT','FSD','FSM','FWA','GCC','GCK','GEG','GFK','GGG','GJT','GNV','GPT','GRB','GRI','GRK',\n"," 'GRR','GSO','GSP','GST','GTF','GTR','GUC','GUM','HDN','HGR','HHH','HIB','HLN','HNL','HOB','HOU',\n"," 'HPN','HRL','HSV','HTS','HVN','HYA','HYS','IAD','IAG','IAH','ICT','IDA','ILM','IMT','IND','INL',\n"," 'IPT','ISN','ISP','ITH','ITO','JAC','JAN','JAX','JFK','JHM','JLN','JMS','JNU','KOA','KTN','LAN',\n"," 'LAR','LAS','LAW','LAX','LBB','LBE','LBF','LBL','LCH','LCK','LEX','LFT','LGA','LGB','LIH','LIT',\n"," 'LNK','LNY','LRD','LSE','LWB','LWS','LYH','MAF','MBS','MCI','MCO','MDT','MDW','MEI','MEM','MFE',\n"," 'MFR','MGM','MHK','MHT','MIA','MKE','MKG','MKK','MLB','MLI','MLU','MMH','MOB','MOT','MQT','MRY',\n"," 'MSN','MSO','MSP','MSY','MTJ','MVY','MYR','OAJ','OAK','OGD','OGG','OGS','OKC','OMA','OME','ONT',\n"," 'ORD','ORF','ORH','OTH','OTZ','OWB','PAE','PAH','PBG','PBI','PDX','PGD','PGV','PHF','PHL','PHX',\n"," 'PIA','PIB','PIE','PIH','PIR','PIT','PLN','PNS','PPG','PQI','PRC','PSC','PSE','PSG','PSM','PSP',\n"," 'PUB','PUW','PVD','PVU','PWM','RAP','RDD','RDM','RDU','RFD','RHI','RIC','RIW','RKS','RNO','ROA',\n"," 'ROC','ROW','RST','RSW','SAF','SAN','SAT','SAV','SBA','SBN','SBP','SBY','SCC','SCE','SCK','SDF',\n"," 'SEA','SFB','SFO','SGF','SGU','SHD','SHR','SHV','SIT','SJC','SJT','SJU','SLC','SLN','SMF','SMX',\n"," 'SNA','SPI','SPN','SPS','SRQ','STC','STL','STS','STT','STX','SUN','SUX','SWF','SWO','SYR','TLH',\n"," 'TOL','TPA','TRI','TTN','TUL','TUS','TVC','TWF','TXK','TYR','TYS','UIN','USA','VEL','VLD','VPS',\n"," 'WRG','WYS','XNA','XWA','YAK','YKM','YUM'\n","}\n","\n","# -----------------------------------------------------\n","# 3. Filter dataset to US airports with matching IATA\n","# -----------------------------------------------------\n","airports_us = airports[airports['iso_country'] == 'US']\n","\n","filtered = airports_us[\n","    airports_us['iata_code'].isin(iata_codes)\n","][[\n","    'iata_code', 'name', 'municipality', 'iso_region',\n","    'latitude_deg', 'longitude_deg'\n","]]\n","\n","# rename columns to cleaner names\n","filtered = filtered.rename(columns={\n","    'iata_code': 'IATA',\n","    'name': 'Airport_Name',\n","    'municipality': 'City',\n","    'iso_region': 'State',\n","    'latitude_deg': 'Latitude',\n","    'longitude_deg': 'Longitude'\n","})\n","\n","# -----------------------------------------------------\n","# 4. Save to CSV\n","# -----------------------------------------------------\n","filtered.to_csv(\"airports_filtered.csv\", index=False)\n","\n","filtered.head()\n"],"metadata":{"id":"erZqNUlFo4E_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Airlines data"],"metadata":{"id":"l09G2m9Mehhk"}},{"cell_type":"code","source":["airlines_data = pd.read_csv('https://query.data.world/s/wpnzpdbcchgnj4vqacqww66vdhpovr?dws=00000')"],"metadata":{"id":"OagKHK7kehyl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["airlines_data"],"metadata":{"id":"Wr3JeQ8tenOg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Merge the main dataframe with the airlines description dataframe\n","df = pd.merge(df, airlines_data, left_on='AIRLINE_ID', right_on='Code', how='left')\n","\n","# Rename the 'Description' column to 'Airline_Name' for clarity\n","df.rename(columns={'Description': 'Airline_Name'}, inplace=True)\n","\n","# Optionally, drop the original 'AIRLINE_ID' and 'Code' columns if no longer needed\n","#df.drop(['AIRLINE_ID', 'Code'], axis=1, inplace=True)\n","\n","# Display the first few rows to verify the changes\n","display(df.head())"],"metadata":{"id":"0fOllstmexRM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mbTcUhjlZT_l"},"source":["Checklist:\n","- https://ft-interactive.github.io/visual-vocabulary/: use at least all of the categories in the summary of\n","- Think of the storyline according to this and the theory\n","\n","- TO do the dashboard check pyviz tools. (we liked it more streamlit)\n"]},{"cell_type":"code","source":["df_full_2018 = df[df['FL_DATE'].dt.year == 2018]\n","df_full_2020 = df[df['FL_DATE'].dt.year == 2020]\n","\n","print(\"Shape of df_full_2018:\", df_full_2018.shape)\n","print(\"Shape of df_full_2020:\", df_full_2020.shape)\n","\n","display(df_full_2018.head())\n","display(df_full_2020.head())"],"metadata":{"id":"aldtGOKWn1DU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"486aa0b8"},"source":["## Merge Airport Data\n","\n","Merge the main DataFrame (`df`) with the `filtered` (airport data) DataFrame to add detailed origin and destination airport information."]},{"cell_type":"code","metadata":{"id":"ccfc62f5"},"source":["# Merge for Origin Airport information\n","df = pd.merge(df, filtered, left_on='ORIGIN_AIRPORT', right_on='IATA', how='left',\n","              suffixes=('', '_ORIGIN_AIRPORT'))\n","\n","# Rename the newly merged columns for clarity\n","df.rename(columns={\n","    'Airport_Name_ORIGIN_AIRPORT': 'Origin_Airport_Name',\n","    'City_ORIGIN_AIRPORT': 'Origin_City',\n","    'State_ORIGIN_AIRPORT': 'Origin_State',\n","    'Latitude_ORIGIN_AIRPORT': 'Origin_Latitude',\n","    'Longitude_ORIGIN_AIRPORT': 'Origin_Longitude'\n","}, inplace=True)\n","\n","# Drop the redundant IATA column from the origin merge\n","df.drop(columns=['IATA_ORIGIN_AIRPORT'], inplace=True, errors='ignore')\n","\n","# Merge for Destination Airport information\n","df = pd.merge(df, filtered, left_on='DEST_AIRPORT', right_on='IATA', how='left',\n","              suffixes=('', '_DEST_AIRPORT'))\n","\n","# Rename the newly merged columns for clarity\n","df.rename(columns={\n","    'Airport_Name_DEST_AIRPORT': 'Destination_Airport_Name',\n","    'City_DEST_AIRPORT': 'Destination_City',\n","    'State_DEST_AIRPORT': 'Destination_State',\n","    'Latitude_DEST_AIRPORT': 'Destination_Latitude',\n","    'Longitude_DEST_AIRPORT': 'Destination_Longitude'\n","}, inplace=True)\n","\n","# Drop the redundant IATA column from the destination merge\n","df.drop(columns=['IATA'], inplace=True, errors='ignore')\n","\n","\n","display(df.head())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"273fc13a"},"source":["df_2018_counts = df_full_2018.groupby('Airline_Name').size().reset_index(name='Flight_Count')\n","\n","df_2020_counts = df_full_2020.groupby('Airline_Name').size().reset_index(name='Flight_Count')\n","\n","print(\"Shape of df_2018_counts:\", df_2018_counts.shape)\n","display(df_2018_counts.head())\n","\n","print(\"Shape of df_2020_counts:\", df_2020_counts.shape)\n","display(df_2020_counts.head())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"036d32ab"},"source":["df_2018_counts_all = df_full_2018.groupby('Airline_Name').size().reset_index(name='Flight_Count')\n","df_2018_counts_all = df_2018_counts_all.sort_values(by='Flight_Count', ascending=False)\n","\n","df_2018_top_10 = df_2018_counts_all.head(10)\n","\n","remaining_airlines = df_2018_counts_all.iloc[10:]\n","others_count = remaining_airlines['Flight_Count'].sum()\n","df_2018_others = pd.DataFrame([{'Airline_Name': 'Others', 'Flight_Count': others_count}])\n","\n","df_2018_sankey_data = pd.concat([df_2018_top_10, df_2018_others])\n","\n","print(\"Shape of df_2018_sankey_data:\", df_2018_sankey_data.shape)\n","display(df_2018_sankey_data.head(25))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"602fd759"},"source":["**Reasoning**:\n","Now I need to perform the same calculations for the 2020 data, specifically calculating flight counts, identifying the top 20 airlines, grouping the rest into 'Others', and combining them to form `df_2020_sankey_data`.\n","\n"]},{"cell_type":"code","metadata":{"id":"33ba8ef8"},"source":["df_2020_counts_all = df_full_2020.groupby('Airline_Name').size().reset_index(name='Flight_Count')\n","df_2020_counts_all = df_2020_counts_all.sort_values(by='Flight_Count', ascending=False)\n","\n","df_2020_top_10 = df_2020_counts_all.head(10)\n","\n","remaining_airlines_2020 = df_2020_counts_all.iloc[10:]\n","others_count_2020 = remaining_airlines_2020['Flight_Count'].sum()\n","df_2020_others = pd.DataFrame([{'Airline_Name': 'Others', 'Flight_Count': others_count_2020}])\n","\n","df_2020_sankey_data = pd.concat([df_2020_top_10, df_2020_others])\n","\n","print(\"Shape of df_2020_sankey_data:\", df_2020_sankey_data.shape)\n","display(df_2020_sankey_data.head(25))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"30258f57"},"source":["# Task\n","Prepare unique node labels for all airlines in both 2018 and 2020 (including 'Others'), prefixing them with the year. Create a numerical ID mapping for these nodes, ensuring that for each year, airlines are sorted by flight count in descending order, with 'Others' at the bottom."]},{"cell_type":"markdown","metadata":{"id":"5609c9d9"},"source":["## Prepare Node Labels and IDs\n","\n","### Subtask:\n","Generate unique node labels for all airlines in both 2018 and 2020 (including 'Others'), prefixing them with the year. Create a numerical ID mapping for these nodes, ensuring that for each year, airlines are sorted by flight count in descending order, with 'Others' at the bottom.\n"]},{"cell_type":"markdown","metadata":{"id":"c1fcd114"},"source":["**Reasoning**:\n","Generate unique node labels for 2018 and 2020 by prepending the year to each airline name from the respective sankey dataframes, combine them, and then create a numerical ID mapping for all unique nodes.\n","\n"]},{"cell_type":"code","metadata":{"id":"8cd39c78"},"source":["node_labels_2018 = [f\"2018: {airline}\" for airline in df_2018_sankey_data['Airline_Name']]\n","node_labels_2020 = [f\"2020: {airline}\" for airline in df_2020_sankey_data['Airline_Name']]\n","\n","all_node_labels = node_labels_2018 + node_labels_2020\n","\n","node_to_id = {label: i for i, label in enumerate(all_node_labels)}\n","\n","print(\"\\nAll Node Labels:\")\n","print(all_node_labels)\n","print(\"\\nNode to ID Mapping:\")\n","print(node_to_id)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bf3437dc"},"source":["## Calculate Sankey Links (Flows)\n","\n","### Subtask:\n","Determine the flight volume flows (links) between the 2018 and 2020 nodes. This involves calculating direct flows for airlines present in both years, flows from 2018 specific airlines to '2020: Others', flows from '2018: Others' to 2020 specific airlines, and the flow between '2018: Others' and '2020: Others'.\n"]},{"cell_type":"markdown","metadata":{"id":"8eb602a1"},"source":["**Reasoning**:\n","First, extract the airline names from the 2018 and 2020 sankey dataframes, excluding 'Others', to identify the specific airlines for flow calculations. This is the initial step to prepare for determining common airlines and individual flows.\n","\n"]},{"cell_type":"code","metadata":{"id":"c2d76dc1"},"source":["airlines_2018_named = df_2018_sankey_data[df_2018_sankey_data['Airline_Name'] != 'Others']['Airline_Name'].tolist()\n","airlines_2020_named = df_2020_sankey_data[df_2020_sankey_data['Airline_Name'] != 'Others']['Airline_Name'].tolist()\n","\n","print(\"Named airlines in 2018:\", airlines_2018_named)\n","print(\"Named airlines in 2020:\", airlines_2020_named)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"43a9e364"},"source":["**Reasoning**:\n","Now that the named airlines for both years are extracted, the next step is to identify common airlines, create an empty list for sankey links, and then calculate direct flows for common airlines and flows to '2020: Others' based on the flight counts, using the `node_to_id` mapping for correct indexing.\n","\n"]},{"cell_type":"code","metadata":{"id":"cd8f80cd"},"source":["common_airlines = list(set(airlines_2018_named) & set(airlines_2020_named))\n","sankey_links = []\n","\n","for airline in common_airlines:\n","    # Get flight counts for the common airline in both years\n","    count_2018 = df_2018_sankey_data[df_2018_sankey_data['Airline_Name'] == airline]['Flight_Count'].iloc[0]\n","    count_2020 = df_2020_sankey_data[df_2020_sankey_data['Airline_Name'] == airline]['Flight_Count'].iloc[0]\n","\n","    # Determine source and target IDs\n","    source_id = node_to_id[f\"2018: {airline}\"]\n","    target_id = node_to_id[f\"2020: {airline}\"]\n","\n","    # Add direct flow for the common airline (value is 2020 count)\n","    sankey_links.append({\"source\": source_id, \"target\": target_id, \"value\": count_2020})\n","\n","    # Calculate flow from 2018 specific airline to 2020 Others if 2018 count is greater\n","    if count_2018 > count_2020:\n","        others_2020_id = node_to_id[\"2020: Others\"]\n","        sankey_links.append({\"source\": source_id, \"target\": others_2020_id, \"value\": count_2018 - count_2020})\n","\n","print(\"Sankey Links after processing common airlines:\")\n","print(sankey_links)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a983d029"},"source":["**Reasoning**:\n","To handle flows from '2018: Others' to specific 2020 airlines, I need to identify airlines present in the 2020 top list but not in the 2018 top list. Then, for each such airline, I will add a link from '2018: Others' to the specific 2020 airline with its 2020 flight count.\n","\n"]},{"cell_type":"code","metadata":{"id":"8b69de80"},"source":["airlines_emerged_2020 = [airline for airline in airlines_2020_named if airline not in airlines_2018_named]\n","others_2018_id = node_to_id['2018: Others']\n","\n","for airline in airlines_emerged_2020:\n","    count_2020 = df_2020_sankey_data[df_2020_sankey_data['Airline_Name'] == airline]['Flight_Count'].iloc[0]\n","    target_id = node_to_id[f\"2020: {airline}\"]\n","    sankey_links.append({\"source\": others_2018_id, \"target\": target_id, \"value\": count_2020})\n","\n","print(\"Sankey Links after processing '2018: Others' to specific 2020 airlines:\")\n","print(sankey_links)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c18af69c"},"source":["**Reasoning**:\n","To complete the Sankey links, I need to account for airlines that were in the top 10 in 2018 but are no longer in the top 10 in 2020. Their entire 2018 flight volume should flow to the '2020: Others' category. This step identifies such airlines and adds these flows to the `sankey_links` list.\n","\n"]},{"cell_type":"code","metadata":{"id":"39342886"},"source":["airlines_lost_2018 = [airline for airline in airlines_2018_named if airline not in airlines_2020_named]\n","others_2020_id = node_to_id['2020: Others']\n","\n","for airline in airlines_lost_2018:\n","    count_2018 = df_2018_sankey_data[df_2018_sankey_data['Airline_Name'] == airline]['Flight_Count'].iloc[0]\n","    source_id = node_to_id[f\"2018: {airline}\"]\n","    sankey_links.append({\"source\": source_id, \"target\": others_2020_id, \"value\": count_2018})\n","\n","print(\"Sankey Links after processing '2018: Lost Airlines' to '2020: Others':\")\n","print(sankey_links)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1ad5ea2e"},"source":["**Reasoning**:\n","Following the instructions, I will calculate the flow from '2018: Others' to '2020: Others' by subtracting the flight volume of airlines that emerged from '2018: Others' into specific 2020 categories from the total '2020: Others' flight count. This will ensure the final link is added to the `sankey_links` list, completing the flow calculations.\n","\n"]},{"cell_type":"code","metadata":{"id":"a722393e"},"source":["others_2018_id = node_to_id['2018: Others']\n","others_2020_id = node_to_id['2020: Others']\n","\n","# Calculate flow from 2018 Others to specific 2020 airlines (already done in step before last)\n","flow_from_others_to_named_2020 = sum([link['value'] for link in sankey_links if link['source'] == others_2018_id and link['target'] != others_2020_id])\n","\n","# Calculate the flow from 2018 Others to 2020 Others based on the specified approximation\n","flow_from_2018_others_to_2020_others = df_2020_others['Flight_Count'].iloc[0] - flow_from_others_to_named_2020\n","\n","# Add this final link\n","sankey_links.append({\"source\": others_2018_id, \"target\": others_2020_id, \"value\": flow_from_2018_others_to_2020_others})\n","\n","print(\"Final Sankey Links:\")\n","print(sankey_links)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"068e408f"},"source":["## Generate Sankey Chart\n","\n","### Subtask:\n","Create and display the Sankey chart using Plotly, incorporating the prepared nodes and links to visualize the shift in airline flight volumes from 2018 to 2020.\n"]},{"cell_type":"markdown","metadata":{"id":"ca2a9f32"},"source":["## Summary:\n","\n","### Data Analysis Key Findings\n","\n","*   **Node Preparation:** Unique node labels were successfully generated for 11 airlines in 2018 (prefixed with \"2018: \") and 11 airlines in 2020 (prefixed with \"2020: \"), including an 'Others' category for each year. These 22 unique labels were then mapped to numerical IDs from 0 to 21.\n","*   **Sankey Link Generation:** A comprehensive list of Sankey links (`sankey_links`) was created to represent flight volume transitions between 2018 and 2020.\n","    *   **Common Airlines:** Direct flows were established for airlines present in both years, with the 2020 flight count as the value. If an airline's 2018 count was higher than its 2020 count, the difference was routed from the 2018 specific airline node to the \"2020: Others\" node.\n","    *   **Emerging Airlines:** Airlines that were part of \"2018: Others\" but emerged as specific top airlines in 2020 had their 2020 flight volume linked from \"2018: Others\" to their specific 2020 node (e.g., 'Endeavor Air Inc.: 9E').\n","    *   **Disappearing Airlines:** Airlines that were top in 2018 but not in 2020 had their entire 2018 flight volume linked from their 2018 specific node to \"2020: Others\" (e.g., 'Alaska Airlines Inc.: AS').\n","    *   **'Others' to 'Others' Flow:** The flow between \"2018: Others\" and \"2020: Others\" was calculated to account for the remaining flight volumes, completing the overall transition picture.\n","\n","### Insights or Next Steps\n","\n","*   The prepared nodes and links provide the necessary structured data to effectively visualize the complex shifts in airline flight volumes from 2018 to 2020, including how airlines entered, exited, or changed their standing relative to the \"Others\" category.\n","*   The next step is to use these `node_to_id` mappings and the `sankey_links` list to construct and display the Sankey chart using a visualization library like Plotly, which will visually represent these flight volume transitions.\n"]},{"cell_type":"code","source":["import plotly.graph_objects as go\n","\n","sankey_links_sorted = sorted(sankey_links, key=lambda x: x['value'], reverse=True)\n","print(sankey_links)\n","print(sankey_links_sorted)\n","\n","node_labels_2018_sorted = [f\"2018: {airline}\" for airline in df_2018_sankey_data['Airline_Name']]\n","node_labels_2020_sorted = [f\"2020: {airline}\" for airline in df_2020_sankey_data['Airline_Name']]\n","\n","all_node_labels = node_labels_2018 + node_labels_2020\n","\n","print(all_node_labels)\n","\n","blue_gradient = [\n","    \"#001933\",\n","    \"#00264D\",\n","    \"#003366\",\n","    \"#004080\",\n","    \"#004C99\",\n","    \"#0059B3\",\n","    \"#0066CC\",\n","    \"#3385D6\",\n","    \"#66A3E0\",\n","    \"#99C2EB\",\n","    \"#CCE0F5\"\n","]\n","\n","# Create the Sankey diagram\n","fig = go.Figure(data=[go.Sankey(\n","    node=dict(\n","        pad=10,\n","        thickness=40,\n","        line=dict(color=\"black\", width=1),\n","        label=all_node_labels,  # Use the combined node labels\n","        color=blue_gradient*2\n","    ),\n","    link=dict(\n","        source=[link['source'] for link in sankey_links_sorted],\n","        target=[link['target'] for link in sankey_links_sorted],\n","        value=[link['value'] for link in sankey_links_sorted],\n","        #color=\"gray\"\n","    )\n",")])\n","\n","fig.update_layout(title_text=\"Airline Flight Volume Shift: 2018 vs. 2020\", font_size=10)\n","fig.show()"],"metadata":{"id":"tnS4AMso11fW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import plotly.graph_objects as go\n","import numpy as np\n","from collections import defaultdict\n","\n","# ---- Input assumptions (you already have these) ----\n","# sankey_links: list of dicts with 'source','target','value' (values may be np.int64)\n","# node_labels_2018: list of left-side labels (2018)\n","# node_labels_2020: list of right-side labels (2020)\n","# all_node_labels = node_labels_2018 + node_labels_2020\n","# blue_gradient = list of 11 hex colors (dark->light)\n","\n","# ---- Convert values to plain int and make a copy of links ----\n","links_clean = [{\"source\": int(l[\"source\"]), \"target\": int(l[\"target\"]), \"value\": int(l[\"value\"])} for l in sankey_links]\n","\n","# ---- Indices for left/right sides ----\n","L = len(node_labels_2018)\n","R = len(node_labels_2020)\n","total_nodes = L + R\n","left_indices = list(range(0, L))\n","right_indices = list(range(L, L + R))\n","\n","# ---- Compute totals: outgoing for left, incoming for right ----\n","left_totals = defaultdict(int)\n","right_totals = defaultdict(int)\n","\n","for l in links_clean:\n","    left_totals[l[\"source\"]] += l[\"value\"]\n","    right_totals[l[\"target\"]] += l[\"value\"]\n","\n","# ---- Detect \"Others\" nodes on each side (label contains \"Others\", case-insensitive) ----\n","def find_others_index(labels, base_index=0):\n","    for i, label in enumerate(labels):\n","        if \"others\" in label.lower():\n","            return base_index + i\n","    return None\n","\n","left_others = find_others_index(node_labels_2018, base_index=0)\n","right_others = find_others_index(node_labels_2020, base_index=L)\n","\n","# ---- Build sorted order for each side (exclude Others while sorting) ----\n","def sorted_side(indices, totals, others_index=None):\n","    # nodes that exist on that side\n","    nodes = [i for i in indices if i != others_index]\n","    # sort descending by totals (missing totals -> 0)\n","    nodes_sorted = sorted(nodes, key=lambda x: totals.get(x, 0), reverse=True)\n","    if others_index is not None:\n","        nodes_sorted.append(others_index)  # pin Others to bottom\n","    return nodes_sorted\n","\n","left_sorted = sorted_side(left_indices, left_totals, left_others)\n","right_sorted = sorted_side(right_indices, right_totals, right_others)\n","\n","# ---- New node order: left (sorted) then right (sorted) ----\n","new_node_order = left_sorted + right_sorted\n","\n","# ---- Build mapping old_index -> new_index ----\n","index_map = {old: new for new, old in enumerate(new_node_order)}\n","\n","# ---- Remap labels to new order ----\n","all_node_labels_sorted = [all_node_labels[i] for i in new_node_order]\n","\n","# ---- Remap links to new node indices ----\n","remapped_links = [{\n","    \"source\": index_map[l[\"source\"]],\n","    \"target\": index_map[l[\"target\"]],\n","    \"value\": int(l[\"value\"])\n","} for l in links_clean]\n","\n","# ---- Prepare node colors (repeat gradient to cover all nodes) ----\n","# blue_gradient is 11 colors; repeat to cover total_nodes\n","colors_needed = total_nodes\n","colors_repeated = (blue_gradient * ((colors_needed // len(blue_gradient)) + 1))[:colors_needed]\n","\n","# ---- Build Sankey ----\n","fig = go.Figure(data=[go.Sankey(\n","    node=dict(\n","        pad=10,\n","        thickness=40,\n","        line=dict(color=\"black\", width=1),\n","        label=all_node_labels_sorted,\n","        color=colors_repeated\n","    ),\n","    link=dict(\n","        source=[l[\"source\"] for l in remapped_links],\n","        target=[l[\"target\"] for l in remapped_links],\n","        value=[l[\"value\"] for l in remapped_links]\n","    )\n",")])\n","\n","fig.update_layout(title_text=\"Airline Flight Volume Shift: 2018 vs. 2020 (sorted)\", font_size=10)\n","fig.show()"],"metadata":{"id":"Myl8YD05AZ_2"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}